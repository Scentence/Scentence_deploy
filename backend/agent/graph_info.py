# backend/agent/graph_info.py
import json
import asyncio
from typing import Literal, Any
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END

# [1] ìŠ¤í‚¤ë§ˆ ì„í¬íŠ¸
from .schemas import InfoState, InfoRoutingDecision, IngredientAnalysisResult

# [2] ë„êµ¬ ì„í¬íŠ¸
from .tools import (
    lookup_perfume_info_tool,
    lookup_perfume_by_id_tool,
    lookup_note_info_tool,
    lookup_accord_info_tool,
    lookup_similar_perfumes_tool,
)

# [3] í”„ë¡¬í”„íŠ¸ ì„í¬íŠ¸
from .prompts import (
    INFO_SUPERVISOR_PROMPT,
    PERFUME_DESCRIBER_PROMPT_BEGINNER,
    PERFUME_DESCRIBER_PROMPT_EXPERT,
    SIMILARITY_CURATOR_PROMPT_BEGINNER,
    SIMILARITY_CURATOR_PROMPT_EXPERT,
    INGREDIENT_SPECIALIST_PROMPT,
)

# [4] Expression Loader for dynamic dictionary injection
from .expression_loader import ExpressionLoader

load_dotenv()

# [LLM ì´ì›í™”]
INFO_LLM = ChatOpenAI(model="gpt-4.1", temperature=0, streaming=True)
ROUTER_LLM = ChatOpenAI(model="gpt-4.1", temperature=0, streaming=False)


# ==========================================
# 4. Utility Functions (moved to utils.py)
# ==========================================

from .utils import (
    extract_save_refs,
    parse_ordinal,
    resolve_target_from_ordinal_or_pronoun,
    classify_info_status,
)


# ==========================================
# 5. Node Functions
# ==========================================


def info_supervisor_node(state: InfoState):
    """[Router] ë¶„ë¥˜ ë…¸ë“œ"""
    print(f"\n   â–¶ï¸ [Info Subgraph] Supervisor ë…¸ë“œ ì‹œì‘", flush=True)
    user_query = state.get("user_query", "")

    chat_history = state.get("messages", [])
    context_str = ""
    if chat_history:
        recent_msgs = chat_history[-3:] if len(chat_history) > 3 else chat_history
        for msg in recent_msgs:
            role = "User" if isinstance(msg, HumanMessage) else "AI"
            if msg.content:
                context_str += f"- {role}: {msg.content}\n"

    final_system_prompt = INFO_SUPERVISOR_PROMPT
    if context_str:
        final_system_prompt += f"\n\n[Recent Chat Context]\n{context_str}"

    final_system_prompt += "\n\n[Instruction]\nResolve the target name from context and classify based on the PRIORITY rules."

    messages = [
        SystemMessage(content=final_system_prompt),
        HumanMessage(content=user_query),
    ]

    # [Phase 0] Ordinal ë²ˆí˜¸ ë¨¼ì € ì²´í¬ (LLM í˜¸ì¶œ ì „)
    save_refs = extract_save_refs(chat_history)
    ordinal = parse_ordinal(user_query)
    
    if ordinal and save_refs:
        # number í•„ë“œ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰
        target_ref = None
        for ref in save_refs:
            if ref.get("number") == ordinal:
                target_ref = ref
                break
        
        if target_ref:
            # Ordinalë¡œ ì§ì ‘ íƒ€ê²Ÿ ê²°ì • (LLM í˜¸ì¶œ ë¶ˆí•„ìš”)
            target_id = target_ref['id']
            target_name = target_ref['name']
            
            # info_type ê²°ì •: "ë¹„ìŠ·í•œ/ì¶”ì²œ/ëŒ€ì²´" í‚¤ì›Œë“œ ì²´í¬
            if any(kw in user_query for kw in ['ë¹„ìŠ·', 'ì¶”ì²œ', 'ëŒ€ì²´', 'ê°™ì€']):
                info_type = "similarity"
            else:
                info_type = "perfume"
            
            print(f"   âœ… [Ordinal] {ordinal}ë²ˆì§¸ í–¥ìˆ˜ ì§ì ‘ ì„ íƒ: {target_name} (type: {info_type})", flush=True)
            
            return {
                "info_type": info_type,
                "target_id": target_id,
                "target_name": target_name,
                "target_brand": None,
                "target_name_kr": None
            }
        else:
            fail_msg = f"ì§€ê¸ˆ ì¶”ì²œì€ 1~{len(save_refs)}ë²ˆì§¸ê¹Œì§€ ìˆì–´ìš”. ì›í•˜ì‹œëŠ” ë²ˆí˜¸ë¡œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”."
            return {"info_type": "unknown", "target_name": "unknown", "fail_msg": fail_msg}
    
    try:
        decision = ROUTER_LLM.with_structured_output(InfoRoutingDecision).invoke(
            messages
        )

        # [Phase 1] ê¸°ë³¸ ì§€ì‹ ì§ˆë¬¸ì´ë©´ save_refs ì²´í¬ ì—†ì´ ë°”ë¡œ ì²˜ë¦¬
        if decision.info_type in ["note", "accord", "ingredient"]:
            print(f"   ğŸ“š Basic knowledge query detected: {decision.info_type}", flush=True)
            return {
                "info_type": decision.info_type,
                "target_name": decision.target_name,
                "target_brand": decision.target_brand,
                "target_name_kr": decision.target_name_kr
            }

        # [Phase 3] ë¸Œëœë“œ ë° ì´ì¤‘ ì–¸ì–´ ì¶”ì¶œ
        final_target = decision.target_name
        final_brand = decision.target_brand
        final_target_kr = decision.target_name_kr

        resolved = resolve_target_from_ordinal_or_pronoun(
            user_query, final_target, save_refs
        )

        if resolved:
            ordinal = parse_ordinal(user_query)

            info_type = decision.info_type
            if any(kw in user_query for kw in ['ë¹„ìŠ·', 'ì¶”ì²œ', 'ëŒ€ì²´', 'ê°™ì€']):
                info_type = "similarity"
            elif resolved:
                info_type = "perfume"

            return {
                "info_type": info_type,
                "target_id": resolved['id'],
                "target_name": resolved['name'],
                "target_brand": final_brand,
                "target_name_kr": final_target_kr
            }

        if not save_refs and (parse_ordinal(user_query) or any(p in user_query for p in ['ì´ê±°', 'ê·¸ê±°', 'ì´ í–¥ìˆ˜', 'ì €ê±°'])):
            fail_msg = "ìµœê·¼ì— ì¶”ì²œë“œë¦° í–¥ìˆ˜ ëª©ë¡ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. í–¥ìˆ˜ ì´ë¦„ì„ ì§ì ‘ ë§ì”€í•´ ì£¼ì‹œë©´ ë°”ë¡œ ì°¾ì•„ë“œë¦´ê²Œìš”."
            return {"info_type": "unknown", "target_name": "unknown", "fail_msg": fail_msg}

        ordinal = parse_ordinal(user_query)
        if ordinal and ordinal > len(save_refs):
            fail_msg = f"ì§€ê¸ˆ ì¶”ì²œì€ 1~{len(save_refs)}ë²ˆì§¸ê¹Œì§€ ìˆì–´ìš”. ì›í•˜ì‹œëŠ” ë²ˆí˜¸ë¡œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”."
            return {"info_type": "unknown", "target_name": "unknown", "fail_msg": fail_msg}

        if not final_target or final_target in [
            "ì´ê±°",
            "ê·¸ê±°",
            "ì´ í–¥ìˆ˜",
            "ì¶”ì²œí•´ì¤˜",
            "ë¹„ìŠ·í•œê±°",
        ]:
            return {"info_type": "unknown", "target_name": "unknown"}

        return {
            "info_type": decision.info_type,
            "target_name": final_target,
            "target_brand": final_brand,
            "target_name_kr": final_target_kr
        }

    except Exception as e:
        print(f"      âŒ Supervisor ì—ëŸ¬ ë°œìƒ: {e}", flush=True)
        return {"info_type": "unknown", "target_name": "unknown"}


async def perfume_search_node(state: InfoState):
    """[Search] í–¥ìˆ˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    print(f"\n   ğŸ” [Perfume Search] ê²€ìƒ‰ ì‹œì‘", flush=True)

    target = state["target_name"]
    target_id = state.get("target_id")

    try:
        if target_id:
            search_result = await lookup_perfume_by_id_tool.ainvoke({"perfume_id": target_id})
        else:
            search_result = await lookup_perfume_info_tool.ainvoke(target)

        # [Wave 2] ê²€ìƒ‰ ê²°ê³¼ ìƒíƒœ ë¶„ë¥˜ (ê°ì²´ ê¸°ë°˜)
        status = classify_info_status(search_result)

        if status != "OK":
            # Retry with name if we have both ID and name
            if target_id and target:
                search_result = await lookup_perfume_info_tool.ainvoke(target)
                status = classify_info_status(search_result)

        if status != "OK":
            return {"info_status": status}

        # ê²€ìƒ‰ ì„±ê³µ - info_payloadì— JSON ë¬¸ìì—´ë¡œ ì €ì¥
        return {
            "info_payload": json.dumps(search_result, ensure_ascii=False),
            "info_status": "OK"
        }

    except Exception as e:
        print(f"      âŒ Perfume Search ì—ëŸ¬: {e}", flush=True)
        return {"info_status": "ERROR"}


async def perfume_describer_node(state: InfoState):
    """[Writer] í–¥ìˆ˜ ìƒì„¸ ì •ë³´ ì¶œë ¥ (DB/ë„êµ¬ í˜¸ì¶œ ê¸ˆì§€)"""
    print(f"\n   âœï¸ [Perfume Describer - Writer] ì¶œë ¥ ìƒì„± ì¤‘", flush=True)

    target = state["target_name"]
    user_mode = state.get("user_mode", "BEGINNER")
    search_result_json = state.get("info_payload", "")

    if not search_result_json:
        print("      âš ï¸ [Perfume Describer] info_payload ì—†ìŒ", flush=True)
        return {"info_status": "ERROR"}

    try:
        if user_mode == "EXPERT":
            print("      ğŸ˜ [Mode] ì „ë¬¸ê°€ìš© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì ìš©", flush=True)
            selected_prompt = PERFUME_DESCRIBER_PROMPT_EXPERT
        else:
            print("      ğŸ¥ [Mode] ë¹„ê¸°ë„ˆìš© ë„ìŠ¨íŠ¸ í”„ë¡¬í”„íŠ¸ ì ìš©", flush=True)
            selected_prompt = PERFUME_DESCRIBER_PROMPT_BEGINNER

        # [â˜… Dynamic Expression Injection]
        # Parse perfume data to extract notes and accords
        try:
            perfume_data = json.loads(search_result_json)
            perfume_name = perfume_data.get("name", "Unknown")
            brand = perfume_data.get("brand", "Unknown")

            loader = ExpressionLoader()
            expression_guide = []
            injected_count = 0

            all_notes = []
            all_accords = []

            # Extract notes
            for note_type in ["top_notes", "middle_notes", "base_notes"]:
                note_str = perfume_data.get(note_type, "")
                if note_str and note_str != "N/A":
                    notes = [n.strip() for n in note_str.split(",")]
                    all_notes.extend(notes)
                    for note in notes[:5]:  # Limit per type
                        desc = loader.get_note_desc(note)
                        if desc:
                            expression_guide.append(f"- {note}: {desc}")
                            injected_count += 1

            # Extract accords
            accord_str = perfume_data.get("accords", "")
            if accord_str:
                accords = [a.strip() for a in accord_str.split(",")]
                all_accords = accords
                for accord in accords[:5]:
                    desc = loader.get_accord_desc(accord)
                    if desc:
                        expression_guide.append(f"- {accord}: {desc}")
                        injected_count += 1

            expression_text = "\n".join(expression_guide) if expression_guide else ""

        except Exception as e:
            expression_text = ""

        content_parts = [f"ëŒ€ìƒ í–¥ìˆ˜: {target}"]
        if expression_text:
            content_parts.append(f"\n[ê°ê° í‘œí˜„ ì°¸ê³ ]:\n{expression_text}")
        content_parts.append(f"\n[ê²€ìƒ‰ëœ ìƒì„¸ ì •ë³´]:\n{search_result_json}")

        messages = [
            SystemMessage(content=selected_prompt),
            HumanMessage(content="\n".join(content_parts)),
        ]
        response = await INFO_LLM.ainvoke(messages)

        return {"messages": [response], "final_answer": response.content, "info_status": "OK"}

    except Exception as e:
        print(f"      âŒ Perfume Describer ì—ëŸ¬: {e}", flush=True)
        return {"info_status": "ERROR"}


async def ingredient_search_node(state: InfoState):
    """[Search] ë…¸íŠ¸/ì–´ì½”ë“œ ê²€ìƒ‰"""
    print(f"\n   ğŸ” [Ingredient Search] ê²€ìƒ‰ ì‹œì‘", flush=True)

    try:
        user_query = state.get("user_query", "")
        target_name = state.get("target_name", "")

        # 1. ì¿¼ë¦¬ ë¶„ì„
        analysis_prompt = f"""
        You are a query analyzer. Separate 'Notes' and 'Accords'.
        Query: "{user_query}"
        Context Target: "{target_name}"
        Output JSON: {{ "notes": [], "accords": [], "is_ambiguous": false }}
        """

        try:
            analysis = await ROUTER_LLM.with_structured_output(
                IngredientAnalysisResult
            ).ainvoke(analysis_prompt, config={"tags": ["internal_helper"]})
            print(
                f"      - ë¶„ì„ ê²°ê³¼: Notes={analysis.notes}, Accords={analysis.accords}",
                flush=True,
            )
        except Exception as e:
            print(f"      âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {e}", flush=True)
            analysis = IngredientAnalysisResult(notes=[target_name], accords=[])

        # 2. ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œ
        tasks = []
        tasks.append(
            lookup_note_info_tool.ainvoke({"keywords": analysis.notes})
            if analysis.notes
            else asyncio.sleep(0, result="")
        )
        tasks.append(
            lookup_accord_info_tool.ainvoke({"keywords": analysis.accords})
            if analysis.accords
            else asyncio.sleep(0, result="")
        )

        results = await asyncio.gather(*tasks)
        note_result, accord_result = results[0], results[1]

        # 3. ìƒì„¸ ë¡œê¹…
        def print_result_log(category: str, result_obj: Any):
            if not result_obj:
                return
            try:
                # ê°ì²´ë¥¼ ì§ì ‘ ì²˜ë¦¬
                data = result_obj if isinstance(result_obj, dict) else {}
                if not data:
                    print(f"      ğŸ” [{category}]: ê²°ê³¼ ì—†ìŒ (Empty)", flush=True)
                    return
                for key, val in data.items():
                    if isinstance(val, dict):
                        perfumes = val.get("representative_perfumes", [])
                        perfume_log = ", ".join(perfumes) if perfumes else "ì—†ìŒ"
                        print(
                            f"      ğŸ” [{category}] '{key}': (ëŒ€í‘œí–¥ìˆ˜: {perfume_log})",
                            flush=True,
                        )
            except:
                pass

        print_result_log("Note DB", note_result)
        print_result_log("Accord DB", accord_result)

        # 4. ê²€ìƒ‰ ê²°ê³¼ ìƒíƒœ ë¶„ë¥˜ (ê°ì²´ ê¸°ë°˜)
        note_status = classify_info_status(note_result)
        accord_status = classify_info_status(accord_result)

        # ë‘˜ ë‹¤ NO_RESULTS ë˜ëŠ” ERRORë©´ ì‹¤íŒ¨
        if note_status != "OK" and accord_status != "OK":
            if note_status == "ERROR" or accord_status == "ERROR":
                return {"info_status": "ERROR"}
            else:
                return {"info_status": "NO_RESULTS"}

        # 5. ê²€ìƒ‰ ì„±ê³µ - info_payloadì— ê²°ê³¼ ì €ì¥ (JSON ì§ë ¬í™”)
        payload = {
            "analysis": {
                "notes": analysis.notes,
                "accords": analysis.accords,
            },
            "note_result": note_result,  # ì´ë¯¸ ê°ì²´ (dict ë˜ëŠ” list)
            "accord_result": accord_result,  # ì´ë¯¸ ê°ì²´ (dict ë˜ëŠ” list)
        }

        return {
            "info_payload": json.dumps(payload, ensure_ascii=False),
            "info_status": "OK",
        }

    except Exception as e:
        print(f"      âŒ Ingredient Search ì—ëŸ¬: {e}", flush=True)
        return {"info_status": "ERROR"}


async def ingredient_specialist_node(state: InfoState):
    """[Writer] ë…¸íŠ¸/ì–´ì½”ë“œ ì„¤ëª… ì¶œë ¥ (DB/ë„êµ¬ í˜¸ì¶œ ê¸ˆì§€)"""
    print(f"\n   âœï¸ [Ingredient Specialist - Writer] ì¶œë ¥ ìƒì„± ì¤‘", flush=True)

    try:
        info_payload_str = state.get("info_payload", "")
        if not info_payload_str:
            print("      âš ï¸ [Ingredient Specialist] info_payload ì—†ìŒ", flush=True)
            return {"info_status": "ERROR"}

        # info_payload íŒŒì‹±
        payload = json.loads(info_payload_str)
        analysis_notes = payload["analysis"]["notes"]
        analysis_accords = payload["analysis"]["accords"]
        note_result = payload["note_result"]
        accord_result = payload["accord_result"]

        # Dynamic Expression Injection
        loader = ExpressionLoader()
        expression_guide = []

        for note in analysis_notes[:10]:
            desc = loader.get_note_desc(note)
            if desc:
                expression_guide.append(f"- {note}: {desc}")

        for accord in analysis_accords[:10]:
            desc = loader.get_accord_desc(accord)
            if desc:
                expression_guide.append(f"- {accord}: {desc}")

        expression_text = "\n".join(expression_guide) if expression_guide else ""

        context_parts = [
            f"[User Interest]: Notes: {analysis_notes}, Accords: {analysis_accords}",
        ]

        if expression_text:
            context_parts.append(f"\n[ê°ê° í‘œí˜„ ì°¸ê³ ]:\n{expression_text}")

        # ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ LLMì— ì „ë‹¬
        note_result_str = json.dumps(note_result, ensure_ascii=False) if isinstance(note_result, dict) else str(note_result)
        accord_result_str = json.dumps(accord_result, ensure_ascii=False) if isinstance(accord_result, dict) else str(accord_result)

        context_parts.append(f"""
        [Search Results]:
        --- Note Data ---
        {note_result_str}
        --- Accord Data ---
        {accord_result_str}
        """)

        combined_context = "\n".join(context_parts)

        messages = [
            SystemMessage(content=INGREDIENT_SPECIALIST_PROMPT),
            HumanMessage(content=combined_context),
        ]
        response = await INFO_LLM.ainvoke(messages)

        return {"messages": [response], "final_answer": response.content, "info_status": "OK"}

    except Exception as e:
        print(f"      âŒ Ingredient Specialist ì—ëŸ¬: {e}", flush=True)
        return {"info_status": "ERROR"}


async def similarity_search_node(state: InfoState):
    """[Search] ìœ ì‚¬ í–¥ìˆ˜ ê²€ìƒ‰"""
    print(f"\n   ğŸ” [Similarity Search] ê²€ìƒ‰ ì‹œì‘", flush=True)

    try:
        # [Phase 4] ë¸Œëœë“œ ë° ì´ì¤‘ ì–¸ì–´ í™œìš©
        target_name = state["target_name"]
        target_brand = state.get("target_brand", "")
        target_name_kr = state.get("target_name_kr", "")

        # íŒŒì´í”„ êµ¬ë¶„ìë¡œ ì •ë³´ ì „ë‹¬ (ë¸Œëœë“œ|ì˜ì–´ëª…|í•œê¸€ëª…)
        search_input = f"{target_brand}|{target_name}|{target_name_kr}"

        # ë„êµ¬ í˜¸ì¶œ (ê°ì²´ ë°˜í™˜)
        search_result = await lookup_similar_perfumes_tool.ainvoke(search_input)

        # ê²€ìƒ‰ ê²°ê³¼ ìƒíƒœ ë¶„ë¥˜ (ê°ì²´ ê¸°ë°˜)
        status = classify_info_status(search_result)

        if status != "OK":
            return {"info_status": status}

        # ê²€ìƒ‰ ì„±ê³µ - info_payloadì— JSON ë¬¸ìì—´ë¡œ ì €ì¥
        return {
            "info_payload": json.dumps(search_result, ensure_ascii=False),
            "info_status": "OK",
        }

    except Exception as e:
        print(f"      âŒ Similarity Search ì—ëŸ¬: {e}", flush=True)
        return {"info_status": "ERROR"}


async def similarity_curator_node(state: InfoState):
    """[Writer] ìœ ì‚¬ í–¥ìˆ˜ ì¶”ì²œ ì¶œë ¥ (DB/ë„êµ¬ í˜¸ì¶œ ê¸ˆì§€)"""
    print(f"\n   âœï¸ [Similarity Curator - Writer] ì¶œë ¥ ìƒì„± ì¤‘", flush=True)

    try:
        # [Phase 4] í•œê¸€ëª… ìš°ì„  í‘œì‹œ
        target_name_kr = state.get("target_name_kr")
        target_name = state.get("target_name", "")
        target = target_name_kr if target_name_kr else target_name

        user_mode = state.get("user_mode", "BEGINNER")
        search_result_json = state.get("info_payload", "")

        if not search_result_json:
            print("      âš ï¸ [Similarity Curator] info_payload ì—†ìŒ", flush=True)
            return {"info_status": "ERROR"}

        if user_mode == "EXPERT":
            print("      ğŸ˜ [Mode] ì „ë¬¸ê°€ìš© íë ˆì´í„° í”„ë¡¬í”„íŠ¸ ì ìš©", flush=True)
            selected_prompt = SIMILARITY_CURATOR_PROMPT_EXPERT
        else:
            print("      ğŸ¥ [Mode] ë¹„ê¸°ë„ˆìš© ë„ìŠ¨íŠ¸ í”„ë¡¬í”„íŠ¸ ì ìš©", flush=True)
            selected_prompt = SIMILARITY_CURATOR_PROMPT_BEGINNER

        messages = [
            SystemMessage(content=selected_prompt),
            HumanMessage(
                content=f"ì›ë³¸ í–¥ìˆ˜: {target}\n\n[ì¶”ì²œ í›„ë³´êµ° ë°ì´í„°]:\n{search_result_json}"
            ),
        ]
        response = await INFO_LLM.ainvoke(messages)

        return {"messages": [response], "final_answer": response.content, "info_status": "OK"}

    except Exception as e:
        print(f"      âŒ Similarity Curator ì—ëŸ¬: {e}", flush=True)
        return {"info_status": "ERROR"}


async def fallback_handler_node(state: InfoState):
    """[Fallback] ì•ˆë‚´"""
    print(f"\n   âš ï¸ [Info Subgraph] Fallback Handler ì‹¤í–‰", flush=True)

    fail_msg = state.get("fail_msg")
    if fail_msg:
        return {"messages": [AIMessage(content=fail_msg)], "final_answer": fail_msg}

    fallback_msg = "ì£„ì†¡í•©ë‹ˆë‹¤. ë§ì”€í•˜ì‹  í–¥ìˆ˜ê°€ ë¬´ì—‡ì¸ì§€ ì •í™•íˆ íŒŒì•…í•˜ì§€ ëª»í–ˆì–´ìš”. ğŸ˜…\n'ìƒ¤ë„¬ ë„˜ë²„5ë‘ ë¹„ìŠ·í•œ ê±° ì¶”ì²œí•´ì¤˜' ì²˜ëŸ¼ í–¥ìˆ˜ ì´ë¦„ì„ ì½• ì§‘ì–´ì„œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
    return {"messages": [AIMessage(content=fallback_msg)], "final_answer": fallback_msg}


# ==========================================
# 5-1. Result Router and Status-Specific Nodes (Wave 2)
# ==========================================

def info_result_router_node(state: InfoState):
    """
    info_status ê°’ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.
    
    Returns:
        ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ ('info_writer' | 'info_no_results' | 'info_error')
    """
    info_status = state.get("info_status", "OK")
    
    print(f"\n   ğŸ”€ [Info Router] Status: {info_status}", flush=True)
    
    if info_status == "NO_RESULTS":
        return "info_no_results"
    elif info_status == "ERROR":
        return "info_error"
    else:
        return "info_writer"


async def info_no_results_node(state: InfoState):
    """
    ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ ëŒ€ì•ˆì„ ì œì‹œí•˜ëŠ” ë…¸ë“œì…ë‹ˆë‹¤.
    """
    print(f"\n   âŒ [Info No Results] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ ì²˜ë¦¬", flush=True)

    # [Phase 4] í•œê¸€ëª… ìš°ì„  í‘œì‹œ
    target_name_kr = state.get("target_name_kr")
    target_name = state.get("target_name", "í•´ë‹¹ í•­ëª©")
    display_name = target_name_kr if target_name_kr else target_name

    info_type = state.get("info_type", "unknown")

    if info_type == "perfume":
        msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{display_name}'ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜¢\n\në‹¤ë¥¸ í–¥ìˆ˜ ì´ë¦„ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ ë³´ì‹œê±°ë‚˜, 'í”Œë¡œë„ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜' ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë¬¼ì–´ë´ ì£¼ì„¸ìš”!"
    elif info_type in ["note", "accord", "ingredient"]:
        msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{display_name}' ì„±ë¶„ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ê°€ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ğŸ˜¢\n\n'ìš°ë””', 'í”Œë¡œë„', 'ì‹œíŠ¸ëŸ¬ìŠ¤' ê°™ì€ ì¼ë°˜ì ì¸ ë…¸íŠ¸ë‚˜ ì–´ì½”ë“œë¡œ ë‹¤ì‹œ ë¬¼ì–´ë´ ì£¼ì„¸ìš”!"
    elif info_type == "similarity":
        msg = f"í˜„ì¬ ì €í¬ ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” '{display_name}'ê³¼ ê²°ì´ ë¹„ìŠ·í•œ í–¥ìˆ˜ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë„¤ìš”. ğŸ˜…\n\në‹¤ë¥¸ í–¥ìˆ˜ë¡œ ë‹¤ì‹œ ì°¾ì•„ë´ ë“œë¦´ê¹Œìš”?"
    else:
        msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{display_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜¢\n\ní–¥ìˆ˜ ì´ë¦„ì„ ì •í™•íˆ ë§ì”€í•´ ì£¼ì‹œê±°ë‚˜, ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"

    return {"messages": [AIMessage(content=msg)], "final_answer": msg}


async def info_error_node(state: InfoState):
    """
    ê¸°ìˆ ì  ì˜¤ë¥˜ ë°œìƒ ì‹œ ê³ ì • ë¬¸êµ¬ë¥¼ ì¶œë ¥í•˜ëŠ” ë…¸ë“œì…ë‹ˆë‹¤.
    """
    print(f"\n   âŒ [Info Error] ê¸°ìˆ ì  ì˜¤ë¥˜ ì²˜ë¦¬", flush=True)

    msg = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ™"

    return {"messages": [AIMessage(content=msg)], "final_answer": msg}


async def info_writer_node(state: InfoState):
    """
    OK ìƒíƒœì¼ ë•Œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í˜•ì‹í™”/ìš”ì•½í•˜ëŠ” ë…¸ë“œì…ë‹ˆë‹¤.
    ê·¼ê±° ì—†ëŠ” ìƒˆ ì‚¬ì‹¤ ìƒì„± ê¸ˆì§€ (ZERO HALLUCINATION).
    """
    print(f"\n   âœï¸ [Info Writer] ê²°ê³¼ í˜•ì‹í™”", flush=True)

    final_answer = state.get("final_answer")
    if final_answer:
        print(f"      â„¹ï¸ [Info Writer] ê¸°ì¡´ ë‹µë³€ ì‚¬ìš© (ì´ë¯¸ ì²˜ë¦¬ë¨)", flush=True)
        return {"messages": [AIMessage(content=final_answer)]}

    print(f"      âš ï¸ [Info Writer] final_answer ì—†ìŒ, fallback ì²˜ë¦¬", flush=True)
    msg = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    return {"messages": [AIMessage(content=msg)], "final_answer": msg}


# ==========================================
# 6. Graph Build (Info Subgraph) - Search/Writer ë¶„ë¦¬
# ==========================================
info_workflow = StateGraph(InfoState)

# [Router]
info_workflow.add_node("info_supervisor", info_supervisor_node)

# [Search Nodes]
info_workflow.add_node("perfume_search", perfume_search_node)
info_workflow.add_node("ingredient_search", ingredient_search_node)
info_workflow.add_node("similarity_search", similarity_search_node)

# [Writer Nodes]
info_workflow.add_node("perfume_describer", perfume_describer_node)
info_workflow.add_node("ingredient_specialist", ingredient_specialist_node)
info_workflow.add_node("similarity_curator", similarity_curator_node)

# [Status Handler Nodes]
info_workflow.add_node("info_no_results", info_no_results_node)
info_workflow.add_node("info_error", info_error_node)
info_workflow.add_node("info_writer", info_writer_node)
info_workflow.add_node("fallback_handler", fallback_handler_node)

# [Routing] START â†’ Supervisor
info_workflow.add_edge(START, "info_supervisor")

# [Routing] Supervisor â†’ Search Nodes
info_workflow.add_conditional_edges(
    "info_supervisor",
    lambda x: x["info_type"],
    {
        "perfume": "perfume_search",
        "brand": "perfume_search",
        "note": "ingredient_search",
        "accord": "ingredient_search",
        "ingredient": "ingredient_search",
        "similarity": "similarity_search",
        "unknown": "fallback_handler",
    },
)

# [Routing] Search Nodes â†’ Writer Nodes (status ê¸°ë°˜)
info_workflow.add_conditional_edges(
    "perfume_search",
    info_result_router_node,
    {
        "info_writer": "perfume_describer",  # OKë©´ Writerë¡œ
        "info_no_results": "info_no_results",
        "info_error": "info_error",
    },
)

info_workflow.add_conditional_edges(
    "ingredient_search",
    info_result_router_node,
    {
        "info_writer": "ingredient_specialist",  # OKë©´ Writerë¡œ
        "info_no_results": "info_no_results",
        "info_error": "info_error",
    },
)

info_workflow.add_conditional_edges(
    "similarity_search",
    info_result_router_node,
    {
        "info_writer": "similarity_curator",  # OKë©´ Writerë¡œ
        "info_no_results": "info_no_results",
        "info_error": "info_error",
    },
)

# [Routing] Writer Nodes â†’ info_writer (passthrough)
info_workflow.add_edge("perfume_describer", "info_writer")
info_workflow.add_edge("ingredient_specialist", "info_writer")
info_workflow.add_edge("similarity_curator", "info_writer")

# [Routing] Status Handler Nodes â†’ END
info_workflow.add_edge("fallback_handler", END)
info_workflow.add_edge("info_writer", END)
info_workflow.add_edge("info_no_results", END)
info_workflow.add_edge("info_error", END)

info_graph = info_workflow.compile()
