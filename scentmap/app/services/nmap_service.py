import time
import logging
import os  # [ê°œì„ ] í™˜ê²½ ë³€ìˆ˜ ì§€ì›
from collections import defaultdict
from typing import Dict, List, Optional, Tuple
from psycopg2.extras import RealDictCursor
from scentmap.db import get_db_connection, get_recom_db_connection, get_nmap_db_connection  # [ê°œì„ ] í–¥ìˆ˜ì§€ë„ ì „ìš© ì»¤ë„¥ì…˜ ì¶”ê°€
from scentmap.app.schemas.nmap_schema import NMapResponse, NMapNode, NMapEdge, NMapAnalysisSummary

"""
NMapService: í–¥ìˆ˜ ë§µ(NMap) ë°ì´í„° êµ¬ì¶• ë° ë¶„ì„ ì„œë¹„ìŠ¤
[ê°œì„ ] ì„±ëŠ¥ ìµœì í™”: ìŠ¤ë§ˆíŠ¸ ë¡œë”© + ë©”ëª¨ë¦¬ ìºì‹± + DB ê²©ë¦¬
[ê°œì„ ] EC2 ë°°í¬ ìµœì í™”: í™˜ê²½ ë³€ìˆ˜ ì§€ì› + ë¡œê¹… ë ˆë²¨ ì¡°ì •
"""

logger = logging.getLogger(__name__)

# [ê°œì„ ] ìœ ì‚¬ë„ ì—£ì§€ ê°œìˆ˜ ìµœì í™”: 30 â†’ 20 (ë°ì´í„° í¬ê¸° ê°ì†Œ)
SIMILARITY_TOP_K = 20
FILTER_OPTIONS_TTL = 300
_filter_cache: Optional[Dict] = None
_filter_cache_time: float = 0

# [ê°œì„ ] NMap ë°ì´í„° ìºì‹± (í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥)
NMAP_CACHE_TTL = int(os.getenv("NMAP_CACHE_TTL", "1800"))  # ê¸°ë³¸ 30ë¶„
NMAP_CACHE_MAX_SIZE = int(os.getenv("NMAP_CACHE_MAX_SIZE", "50"))  # í”„ë¡œë•ì…˜: 50ê°œ
_nmap_cache: Dict[str, NMapResponse] = {}
_nmap_cache_time: Dict[str, float] = {}

def get_filter_options() -> Dict[str, List[str]]:
    """í–¥ìˆ˜ ë§µ í•„í„°ë§ì„ ìœ„í•œ ì˜µì…˜ ëª©ë¡ ì¡°íšŒ"""
    global _filter_cache, _filter_cache_time
    if _filter_cache and (time.time() - _filter_cache_time < FILTER_OPTIONS_TTL):
        return _filter_cache

    with get_db_connection() as conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # ë¸Œëœë“œ
            cur.execute("""
                SELECT perfume_brand, COUNT(*) as cnt 
                FROM TB_PERFUME_BASIC_M 
                WHERE perfume_brand IS NOT NULL 
                GROUP BY perfume_brand 
                ORDER BY cnt DESC, perfume_brand
            """)
            brands = [r["perfume_brand"] for r in cur.fetchall()]
            
            # ê³„ì ˆ
            cur.execute("""
                SELECT season, COUNT(DISTINCT perfume_id) as cnt 
                FROM TB_PERFUME_SEASON_R 
                WHERE season IS NOT NULL 
                GROUP BY season 
                ORDER BY cnt DESC, season
            """)
            seasons = [r["season"] for r in cur.fetchall()]
            
            # ìƒí™©
            cur.execute("""
                SELECT occasion, COUNT(DISTINCT perfume_id) as cnt 
                FROM TB_PERFUME_OCA_R 
                WHERE occasion IS NOT NULL 
                GROUP BY occasion 
                ORDER BY cnt DESC, occasion
            """)
            occasions = [r["occasion"] for r in cur.fetchall()]
            
            # ì„±ë³„
            cur.execute("""
                SELECT gender, COUNT(DISTINCT perfume_id) as cnt 
                FROM TB_PERFUME_GENDER_R 
                WHERE gender IS NOT NULL 
                GROUP BY gender 
                ORDER BY cnt DESC, gender
            """)
            genders = [r["gender"] for r in cur.fetchall()]
            
            # ì–´ì½”ë“œ
            cur.execute("""
                SELECT accord, COUNT(DISTINCT perfume_id) as cnt 
                FROM TB_PERFUME_ACCORD_M 
                WHERE accord IS NOT NULL 
                GROUP BY accord 
                ORDER BY cnt DESC, accord
            """)
            accords = [r["accord"] for r in cur.fetchall()]

    _filter_cache = {
        "brands": brands, 
        "seasons": seasons, 
        "occasions": occasions, 
        "genders": genders, 
        "accords": accords
    }
    _filter_cache_time = time.time()
    return _filter_cache

# [ê°œì„ ] ì¸ê¸° í–¥ìˆ˜ ìš°ì„  ì¡°íšŒ (ìŠ¤ë§ˆíŠ¸ ë¡œë”©)
def _fetch_popular_perfume_ids(limit: int = 300) -> List[int]:
    """ì¸ê¸°/ëŒ€í‘œ í–¥ìˆ˜ ID ì¡°íšŒ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)"""
    popular_ids: List[int] = []
    try:
        # TB_MEMBER_MY_PERFUME_TëŠ” recom_db ì†Œì†
        with get_recom_db_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT perfume_id, COUNT(*) as cnt
                    FROM TB_MEMBER_MY_PERFUME_T
                    GROUP BY perfume_id
                    ORDER BY cnt DESC
                    LIMIT %s
                """, (limit,))
                popular_ids = [row[0] for row in cur.fetchall()]
    except Exception as e:
        logger.warning(f"ì¸ê¸° í–¥ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨ (recom_db): {e}")

    # ë‹¤ì–‘ì„± í™•ë³´: ë¶€ì¡±ë¶„ì€ nmap_dbì˜ ë¸Œëœë“œë³„ ëŒ€í‘œ í–¥ìˆ˜ë¡œ ì±„ì›€
    if len(popular_ids) < limit:
        with get_nmap_db_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT DISTINCT ON (perfume_brand) perfume_id
                    FROM TB_PERFUME_BASIC_M
                    WHERE perfume_id NOT IN %s
                    ORDER BY perfume_brand, perfume_id
                    LIMIT %s
                """, (tuple(popular_ids) if popular_ids else (0,), limit - len(popular_ids)))
                popular_ids.extend([row[0] for row in cur.fetchall()])

    if not popular_ids:
        # fallback: nmap_dbì—ì„œ ë‹¨ìˆœ ID ìˆœ
        with get_nmap_db_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("SELECT perfume_id FROM TB_PERFUME_BASIC_M ORDER BY perfume_id LIMIT %s", (limit,))
                popular_ids = [row[0] for row in cur.fetchall()]

    return popular_ids[:limit]

def _fetch_member_perfume_ids(member_id: int) -> List[int]:
    """íšŒì›ì´ ë“±ë¡í•œ í–¥ìˆ˜ ID ì¡°íšŒ"""
    try:
        with get_recom_db_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("SELECT perfume_id FROM TB_MEMBER_MY_PERFUME_T WHERE member_id = %s", (member_id,))
                return [row[0] for row in cur.fetchall()]
    except Exception as e:
        logger.warning(f"íšŒì› í–¥ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def _fetch_perfume_basic_by_ids(perfume_ids: List[int]) -> List[Dict]:
    """íŠ¹ì • í–¥ìˆ˜ IDë“¤ì˜ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ"""
    with get_nmap_db_connection() as conn:  # [ê°œì„ ] ì „ìš© ì»¤ë„¥ì…˜ ì‚¬ìš©
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            sql = "SELECT perfume_id, perfume_name, perfume_brand, img_link FROM TB_PERFUME_BASIC_M WHERE perfume_id = ANY(%s)"
            cur.execute(sql, (perfume_ids,))
            return [dict(row) for row in cur.fetchall()]

def _fetch_perfume_basic(max_perfumes: Optional[int]) -> List[Dict]:
    """í–¥ìˆ˜ ê¸°ë³¸ ì •ë³´ DB ì¡°íšŒ (ë ˆê±°ì‹œ í˜¸í™˜ìš©)"""
    with get_nmap_db_connection() as conn:  # [ê°œì„ ] ì „ìš© ì»¤ë„¥ì…˜ ì‚¬ìš©
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            sql = "SELECT perfume_id, perfume_name, perfume_brand, img_link FROM TB_PERFUME_BASIC_M ORDER BY perfume_id"
            params = []
            if max_perfumes:
                sql += " LIMIT %s"
                params.append(max_perfumes)
            cur.execute(sql, params)
            return [dict(row) for row in cur.fetchall()]

def _fetch_perfume_accords(perfume_ids: Optional[List[int]]) -> List[Dict]:
    """í–¥ìˆ˜ë³„ ì–´ì½”ë“œ ì •ë³´ DB ì¡°íšŒ"""
    with get_nmap_db_connection() as conn:  # [ê°œì„ ] ì „ìš© ì»¤ë„¥ì…˜ ì‚¬ìš©
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            if perfume_ids is None:
                sql = "SELECT perfume_id, accord, vote FROM TB_PERFUME_ACCORD_M"
                cur.execute(sql)
            else:
                sql = "SELECT perfume_id, accord, vote FROM TB_PERFUME_ACCORD_M WHERE perfume_id = ANY(%s)"
                cur.execute(sql, (perfume_ids,))
            return [dict(row) for row in cur.fetchall()]

def _fetch_perfume_tags(perfume_ids: Optional[List[int]]) -> Dict[int, Dict]:
    """í–¥ìˆ˜ë³„ íƒœê·¸(ê³„ì ˆ, ìƒí™©, ì„±ë³„) ì •ë³´ DB ì¡°íšŒ"""
    tags = defaultdict(lambda: {"seasons": set(), "occasions": set(), "genders": set()})
    with get_nmap_db_connection() as conn:  # [ê°œì„ ] ì „ìš© ì»¤ë„¥ì…˜ ì‚¬ìš©
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Seasons
            sql = "SELECT perfume_id, season FROM TB_PERFUME_SEASON_R"
            if perfume_ids:
                sql += " WHERE perfume_id = ANY(%s)"
                cur.execute(sql, (perfume_ids,))
            else:
                cur.execute(sql)
            for r in cur.fetchall(): tags[int(r["perfume_id"])]["seasons"].add(r["season"])
            
            # Occasions
            sql = "SELECT perfume_id, occasion FROM TB_PERFUME_OCA_R"
            if perfume_ids:
                sql += " WHERE perfume_id = ANY(%s)"
                cur.execute(sql, (perfume_ids,))
            else:
                cur.execute(sql)
            for r in cur.fetchall(): tags[int(r["perfume_id"])]["occasions"].add(r["occasion"])
            
            # Genders
            sql = "SELECT perfume_id, gender FROM TB_PERFUME_GENDER_R"
            if perfume_ids:
                sql += " WHERE perfume_id = ANY(%s)"
                cur.execute(sql, (perfume_ids,))
            else:
                cur.execute(sql)
            for r in cur.fetchall(): tags[int(r["perfume_id"])]["genders"].add(r["gender"])
            
    return {pid: {k: sorted(list(v)) for k, v in t.items()} for pid, t in tags.items()}

def _fetch_member_statuses(member_id: Optional[int], perfume_ids: List[int]) -> Dict[int, str]:
    """íšŒì›ë³„ í–¥ìˆ˜ ë“±ë¡ ìƒíƒœ ì¡°íšŒ"""
    if not member_id or not perfume_ids:
        return {}
    with get_recom_db_connection() as conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(
                "SELECT perfume_id, register_status FROM TB_MEMBER_MY_PERFUME_T WHERE member_id = %s AND perfume_id = ANY(%s)",
                (member_id, perfume_ids),
            )
            return {int(row["perfume_id"]): row["register_status"] for row in cur.fetchall() if row.get("register_status")}

# [ê°œì„ ] ìµœì í™”ëœ ìœ ì‚¬ë„ ì—£ì§€ ì¡°íšŒ (íŠ¹ì • í–¥ìˆ˜ë“¤ë§Œ)
def _fetch_similarity_edges_optimized(perfume_ids: List[int], min_sim: float) -> List[Dict]:
    """ìµœì í™”ëœ ìœ ì‚¬ë„ ì—£ì§€ ì¡°íšŒ (ì–‘ë°©í–¥ + ìƒìœ„ Kê°œ)"""
    with get_nmap_db_connection() as conn:  # [ê°œì„ ] ì „ìš© ì»¤ë„¥ì…˜ ì‚¬ìš©
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            sql = """
                WITH all_edges AS (
                    SELECT perfume_id_a as src, perfume_id_b as dst, score 
                    FROM TB_PERFUME_SIMILARITY 
                    WHERE score >= %s 
                      AND perfume_id_a = ANY(%s)
                      AND perfume_id_b = ANY(%s)
                    UNION ALL
                    SELECT perfume_id_b as src, perfume_id_a as dst, score 
                    FROM TB_PERFUME_SIMILARITY 
                    WHERE score >= %s 
                      AND perfume_id_b = ANY(%s)
                      AND perfume_id_a = ANY(%s)
                ), ranked AS (
                    SELECT src, dst, score, 
                           ROW_NUMBER() OVER (PARTITION BY src ORDER BY score DESC) as rn 
                    FROM all_edges
                )
                SELECT src as perfume_id_a, dst as perfume_id_b, score 
                FROM ranked 
                WHERE rn <= %s
            """
            cur.execute(sql, (
                min_sim, perfume_ids, perfume_ids,
                min_sim, perfume_ids, perfume_ids,
                SIMILARITY_TOP_K
            ))
            return [dict(row) for row in cur.fetchall()]

def _fetch_similarity_edges(perfume_ids: Optional[List[int]], min_sim: float, is_full: bool) -> List[Dict]:
    """í–¥ìˆ˜ ê°„ ìœ ì‚¬ë„ ì—£ì§€ DB ì¡°íšŒ (ë ˆê±°ì‹œ í˜¸í™˜ìš©)"""
    with get_nmap_db_connection() as conn:  # [ê°œì„ ] ì „ìš© ì»¤ë„¥ì…˜ ì‚¬ìš©
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            if is_full:
                sql = """
                    WITH all_edges AS (
                        SELECT perfume_id_a as src, perfume_id_b as dst, score FROM TB_PERFUME_SIMILARITY WHERE score >= %s
                        UNION ALL
                        SELECT perfume_id_b as src, perfume_id_a as dst, score FROM TB_PERFUME_SIMILARITY WHERE score >= %s
                    ), ranked AS (
                        SELECT src, dst, score, ROW_NUMBER() OVER (PARTITION BY src ORDER BY score DESC) as rn FROM all_edges
                    )
                    SELECT src as perfume_id_a, dst as perfume_id_b, score FROM ranked WHERE rn <= %s
                """
                cur.execute(sql, (min_sim, min_sim, SIMILARITY_TOP_K))
            else:
                sql = "SELECT perfume_id_a, perfume_id_b, score FROM TB_PERFUME_SIMILARITY WHERE score >= %s AND perfume_id_a = ANY(%s) AND perfume_id_b = ANY(%s)"
                cur.execute(sql, (min_sim, perfume_ids, perfume_ids))
            return [dict(row) for row in cur.fetchall()]

# [ê°œì„ ] ìºì‹œ í‚¤ ìƒì„± í•¨ìˆ˜
def _generate_cache_key(member_id: Optional[int], max_perfumes: int, min_similarity: float, top_accords: int) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    if member_id:
        return f"member_{member_id}_{max_perfumes}_{min_similarity}_{top_accords}"
    else:
        return f"public_{max_perfumes}_{min_similarity}_{top_accords}"

def get_nmap_data(
    member_id: Optional[int] = None, 
    max_perfumes: Optional[int] = None, 
    min_similarity: float = 0.0, 
    top_accords: int = 5,
    debug: bool = False
) -> NMapResponse:
    """í–¥ìˆ˜ ë§µ ì „ì²´ ë°ì´í„° ë° ë¶„ì„ ìš”ì•½ ì •ë³´ ì¡°íšŒ
    [ê°œì„ ] ìŠ¤ë§ˆíŠ¸ ë¡œë”©: ì¸ê¸° í–¥ìˆ˜ ìš°ì„  + ìµœì í™”ëœ ì¿¼ë¦¬
    """
    start = time.time()
    
    # [ê°œì„ ] 1. ìŠ¤ë§ˆíŠ¸ ë¡œë”©: ë¡œë“œí•  í–¥ìˆ˜ ê²°ì •
    if max_perfumes is None:
        # ì „ì²´ ë¡œë“œ ë°©ì§€ - ê¸°ë³¸ 300ê°œë¡œ ì œí•œ
        max_perfumes = 300
        logger.info("âš ï¸ max_perfumesê°€ Noneì´ë¯€ë¡œ ê¸°ë³¸ê°’ 300ìœ¼ë¡œ ì œí•œ")
    
    # ì¸ê¸° í–¥ìˆ˜ ìš°ì„  ì„ íƒ
    target_ids = _fetch_popular_perfume_ids(max_perfumes)
    
    # íšŒì› í–¥ìˆ˜ ì¶”ê°€ (ìˆìœ¼ë©´)
    if member_id:
        member_perfumes = _fetch_member_perfume_ids(member_id)
        # ì¤‘ë³µ ì œê±° ë° ê°œìˆ˜ ì œí•œ
        target_ids = list(set(target_ids) | set(member_perfumes))[:max_perfumes]
        logger.info(f"ğŸ‘¤ íšŒì› {member_id} í–¥ìˆ˜ {len(member_perfumes)}ê°œ ì¶”ê°€")
    
    logger.info(f"ğŸ¯ ì´ {len(target_ids)}ê°œ í–¥ìˆ˜ ë¡œë“œ ì˜ˆì •")
    
    # 2. ë°ì´í„° ì¡°íšŒ (ìŠ¤ë§ˆíŠ¸ ë¡œë”© ë²„ì „)
    p_rows = _fetch_perfume_basic_by_ids(target_ids)
    p_ids = [int(r["perfume_id"]) for r in p_rows]
    
    a_rows = _fetch_perfume_accords(p_ids)
    t_data = _fetch_perfume_tags(p_ids)
    m_statuses = _fetch_member_statuses(member_id, p_ids)
    
    # 2. í”„ë¡œí•„ ë° ë…¸ë“œ êµ¬ì¶•
    acc_by_p = defaultdict(list)
    for r in a_rows: 
        acc_by_p[r["perfume_id"]].append((r["accord"], r["vote"] or 0))
    
    nodes, edges, used_accords = [], [], set()
    p_map = {}
    
    for r in p_rows:
        pid = int(r["perfume_id"])
        acc_list = acc_by_p[pid]
        total_v = sum(v for _, v in acc_list)
        acc_prof = {a: float(v)/total_v for a, v in acc_list} if total_v > 0 else {}
        tags = t_data.get(pid, {"seasons": [], "occasions": [], "genders": []})
        
        sorted_accords = sorted(acc_prof.keys(), key=lambda x: acc_prof[x], reverse=True)
        primary_accord = sorted_accords[0] if sorted_accords else "Unknown"
        
        p_info = {
            "id": str(pid), 
            "type": "perfume", 
            "label": r["perfume_name"], 
            "brand": r["perfume_brand"], 
            "image": r["img_link"],
            "primary_accord": primary_accord,
            "accords": sorted_accords,
            "seasons": tags["seasons"], 
            "occasions": tags["occasions"], 
            "genders": tags["genders"],
            "register_status": m_statuses.get(pid)
        }
        p_map[pid] = p_info
        nodes.append(NMapNode(**p_info))
        
        # í–¥ìˆ˜-ì–´ì½”ë“œ ì—£ì§€
        for acc in sorted_accords[:top_accords]:
            used_accords.add(acc)
            edges.append(NMapEdge(**{
                "from": str(pid), 
                "to": f"accord_{acc}", 
                "type": "HAS_ACCORD", 
                "weight": acc_prof.get(acc, 0.0)
            }))
            
    # ì–´ì½”ë“œ ë…¸ë“œ ì¶”ê°€
    for acc in sorted(list(used_accords)):
        nodes.append(NMapNode(id=f"accord_{acc}", type="accord", label=acc))
        
    # [ê°œì„ ] 3. ìœ ì‚¬ë„ ì—£ì§€ ì¡°íšŒ ë° ì¶”ê°€ (ìµœì í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©)
    sim_rows = _fetch_similarity_edges_optimized(p_ids, min_similarity)
    for r in sim_rows:
        edges.append(NMapEdge(**{
            "from": str(r["perfume_id_a"]), 
            "to": str(r["perfume_id_b"]), 
            "type": "SIMILAR_TO", 
            "weight": r["score"]
        }))
        
    # 4. ë¶„ì„ ìš”ì•½ ìƒì„±
    acc_cnt, mood_cnt = defaultdict(int), defaultdict(int)
    for p in p_map.values():
        for a in p["accords"][:3]: acc_cnt[a] += 1
        for m in p["occasions"] + p["seasons"]: mood_cnt[m] += 1
    
    sorted_accs = sorted(acc_cnt.keys(), key=lambda x: acc_cnt[x], reverse=True)
    summary = NMapAnalysisSummary(
        top_notes=sorted_accs[:3],
        middle_notes=sorted_accs[3:6],
        base_notes=sorted_accs[6:9],
        mood_keywords=sorted(mood_cnt.keys(), key=lambda x: mood_cnt[x], reverse=True)[:5],
        analysis_text="íƒìƒ‰í•˜ì‹  í–¥ê¸°ë“¤ì˜ ì£¼ìš” íŠ¹ì§•ì…ë‹ˆë‹¤."
    )
    
    build_time = round(time.time()-start, 3)
    meta = {
        "build_time": build_time,
        "perfume_count": len(p_map),
        "edge_count": len(edges),
        "min_similarity": min_similarity,
        "top_accords": top_accords
    }
    
    logger.info(f"âœ… NMap ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(p_map)}ê°œ í–¥ìˆ˜, {len(edges)}ê°œ ì—£ì§€, {build_time}ì´ˆ")
    return NMapResponse(nodes=nodes, edges=edges, summary=summary, meta=meta)

# [ê°œì„ ] ìºì‹±ì´ ì ìš©ëœ í–¥ìˆ˜ ë§µ ë°ì´í„° ì¡°íšŒ
def get_nmap_data_cached(
    member_id: Optional[int] = None,
    max_perfumes: int = 300,
    min_similarity: float = 0.0,
    top_accords: int = 5,
    debug: bool = False
) -> NMapResponse:
    """ìºì‹œê°€ ì ìš©ëœ í–¥ìˆ˜ ë§µ ë°ì´í„° ì¡°íšŒ
    [ê°œì„ ] ë©”ëª¨ë¦¬ ìºì‹±ìœ¼ë¡œ ë°˜ë³µ ìš”ì²­ 95% ì„±ëŠ¥ í–¥ìƒ
    """
    global _nmap_cache, _nmap_cache_time
    
    # 1. ìºì‹œ í‚¤ ìƒì„±
    cache_key = _generate_cache_key(member_id, max_perfumes, min_similarity, top_accords)
    
    # 2. ìºì‹œ í™•ì¸
    now = time.time()
    if cache_key in _nmap_cache:
        if now - _nmap_cache_time[cache_key] < NMAP_CACHE_TTL:
            # [ê°œì„ ] í”„ë¡œë•ì…˜ ë¡œê·¸ ê°ì†Œ: INFO â†’ DEBUG
            logger.debug(f"âœ… Cache HIT: {cache_key} (ë‚˜ì´: {round(now - _nmap_cache_time[cache_key])}ì´ˆ)")
            return _nmap_cache[cache_key]
        else:
            # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
            logger.info(f"â° Cache EXPIRED: {cache_key}")  # ë§Œë£ŒëŠ” INFO ìœ ì§€ (ì¤‘ìš”)
            del _nmap_cache[cache_key]
            del _nmap_cache_time[cache_key]
    
    # 3. ìºì‹œ ë¯¸ìŠ¤ - ë°ì´í„° ì¡°íšŒ
    logger.info(f"âŒ Cache MISS: {cache_key} - ìƒˆë¡œ ì¡°íšŒ")  # ë¯¸ìŠ¤ëŠ” INFO ìœ ì§€ (ëª¨ë‹ˆí„°ë§)
    result = get_nmap_data(member_id, max_perfumes, min_similarity, top_accords, debug)
    
    # 4. ìºì‹œ ì €ì¥
    _nmap_cache[cache_key] = result
    _nmap_cache_time[cache_key] = now
    logger.debug(f"ğŸ’¾ Cache SAVED: {cache_key}")  # [ê°œì„ ] DEBUGë¡œ ë³€ê²½
    
    # [ê°œì„ ] 5. ìºì‹œ í¬ê¸° ê´€ë¦¬ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥)
    if len(_nmap_cache) > NMAP_CACHE_MAX_SIZE:
        # ê°€ì¥ ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ
        oldest_key = min(_nmap_cache_time.keys(), key=lambda k: _nmap_cache_time[k])
        logger.info(f"ğŸ—‘ï¸ Cache EVICTED (í¬ê¸° ì´ˆê³¼ {NMAP_CACHE_MAX_SIZE}): {oldest_key}")
        del _nmap_cache[oldest_key]
        del _nmap_cache_time[oldest_key]
    
    return result
